{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ham or Spam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ The goal of this challenge is to classify emails as spams (1) or normal emails (0)\n",
    "\n",
    "üßπ First, you will apply cleaning techniques to these textual data\n",
    "\n",
    "üë©üèª‚Äçüî¨ Then, you will convert the cleaned texts into a numerical representation\n",
    "\n",
    "‚úâÔ∏è Eventually, you will apply the ***Multinomial Naive Bayes*** model to classify each email as either a spam or a regular email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0) The NTLK library (Natural Language Toolkit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T10:56:19.815765Z",
     "iopub.status.busy": "2025-08-12T10:56:19.814625Z",
     "iopub.status.idle": "2025-08-12T10:56:19.825482Z",
     "shell.execute_reply": "2025-08-12T10:56:19.823180Z",
     "shell.execute_reply.started": "2025-08-12T10:56:19.815698Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:14:00.062289Z",
     "iopub.status.busy": "2025-08-12T11:14:00.061841Z",
     "iopub.status.idle": "2025-08-12T11:14:05.108721Z",
     "shell.execute_reply": "2025-08-12T11:14:05.107037Z",
     "shell.execute_reply.started": "2025-08-12T11:14:00.062253Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/glaznos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/glaznos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/glaznos/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/glaznos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/glaznos/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When importing nltk for the first time, we need to also download a few built-in libraries\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')      # For nltk<3.9.0\n",
    "nltk.download('punkt_tab')  # For nltk>=3.9.0\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:14:05.116684Z",
     "iopub.status.busy": "2025-08-12T11:14:05.115909Z",
     "iopub.status.idle": "2025-08-12T11:14:09.460032Z",
     "shell.execute_reply": "2025-08-12T11:14:09.458994Z",
     "shell.execute_reply.started": "2025-08-12T11:14:05.116607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1368"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/10-Natural-Language-Processing/ham_spam_emails.csv\")\n",
    "df.spam.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:14:09.462928Z",
     "iopub.status.busy": "2025-08-12T11:14:09.461383Z",
     "iopub.status.idle": "2025-08-12T11:14:09.495476Z",
     "shell.execute_reply": "2025-08-12T11:14:09.493136Z",
     "shell.execute_reply.started": "2025-08-12T11:14:09.462864Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>Subject: re : research and development charges...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>Subject: re : receipts from visit  jim ,  than...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>Subject: re : enron case study update  wow ! a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>Subject: re : interest  david ,  please , call...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Subject: news : aurora 5 . 2 update  aurora ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam\n",
       "0     Subject: naturally irresistible your corporate...     1\n",
       "1     Subject: the stock trading gunslinger  fanny i...     1\n",
       "2     Subject: unbelievable new homes made easy  im ...     1\n",
       "3     Subject: 4 color printing special  request add...     1\n",
       "4     Subject: do not have money , get software cds ...     1\n",
       "...                                                 ...   ...\n",
       "5723  Subject: re : research and development charges...     0\n",
       "5724  Subject: re : receipts from visit  jim ,  than...     0\n",
       "5725  Subject: re : enron case study update  wow ! a...     0\n",
       "5726  Subject: re : interest  david ,  please , call...     0\n",
       "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0\n",
       "\n",
       "[5728 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Cleaning the (text) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is made up of emails that are classified as ham [0] or spam[1]. You need to clean the dataset before training a prediction model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Remove Punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a function to remove the punctuation. Apply it to the `text` column and add the output to a new column in the dataframe called `clean_text` ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:14:09.501182Z",
     "iopub.status.busy": "2025-08-12T11:14:09.500317Z",
     "iopub.status.idle": "2025-08-12T11:14:09.819796Z",
     "shell.execute_reply": "2025-08-12T11:14:09.818366Z",
     "shell.execute_reply.started": "2025-08-12T11:14:09.501129Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject naturally irresistible your corporate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject the stock trading gunslinger  fanny is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject unbelievable new homes made easy  im w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject 4 color printing special  request addi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject do not have money  get software cds fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>Subject: re : research and development charges...</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject re  research and development charges t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>Subject: re : receipts from visit  jim ,  than...</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject re  receipts from visit  jim   thanks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>Subject: re : enron case study update  wow ! a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject re  enron case study update  wow  all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>Subject: re : interest  david ,  please , call...</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject re  interest  david   please  call shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Subject: news : aurora 5 . 2 update  aurora ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>Subject news  aurora 5  2 update  aurora versi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam  \\\n",
       "0     Subject: naturally irresistible your corporate...     1   \n",
       "1     Subject: the stock trading gunslinger  fanny i...     1   \n",
       "2     Subject: unbelievable new homes made easy  im ...     1   \n",
       "3     Subject: 4 color printing special  request add...     1   \n",
       "4     Subject: do not have money , get software cds ...     1   \n",
       "...                                                 ...   ...   \n",
       "5723  Subject: re : research and development charges...     0   \n",
       "5724  Subject: re : receipts from visit  jim ,  than...     0   \n",
       "5725  Subject: re : enron case study update  wow ! a...     0   \n",
       "5726  Subject: re : interest  david ,  please , call...     0   \n",
       "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0   \n",
       "\n",
       "                                             clean_text  \n",
       "0     Subject naturally irresistible your corporate ...  \n",
       "1     Subject the stock trading gunslinger  fanny is...  \n",
       "2     Subject unbelievable new homes made easy  im w...  \n",
       "3     Subject 4 color printing special  request addi...  \n",
       "4     Subject do not have money  get software cds fr...  \n",
       "...                                                 ...  \n",
       "5723  Subject re  research and development charges t...  \n",
       "5724  Subject re  receipts from visit  jim   thanks ...  \n",
       "5725  Subject re  enron case study update  wow  all ...  \n",
       "5726  Subject re  interest  david   please  call shi...  \n",
       "5727  Subject news  aurora 5  2 update  aurora versi...  \n",
       "\n",
       "[5728 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "import string\n",
    "string.punctuation\n",
    "\n",
    "def replace_punc(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df.text.map(replace_punc)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) Lower Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a function to lowercase the text. Apply it to `clean_text` ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:14:09.829524Z",
     "iopub.status.busy": "2025-08-12T11:14:09.828896Z",
     "iopub.status.idle": "2025-08-12T11:14:09.839488Z",
     "shell.execute_reply": "2025-08-12T11:14:09.838026Z",
     "shell.execute_reply.started": "2025-08-12T11:14:09.829454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'john'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'JOHN'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:14:09.842171Z",
     "iopub.status.busy": "2025-08-12T11:14:09.841269Z",
     "iopub.status.idle": "2025-08-12T11:14:09.897529Z",
     "shell.execute_reply": "2025-08-12T11:14:09.895976Z",
     "shell.execute_reply.started": "2025-08-12T11:14:09.842119Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject naturally irresistible your corporate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject the stock trading gunslinger  fanny is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject unbelievable new homes made easy  im w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject 4 color printing special  request addi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject do not have money  get software cds fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>Subject: re : research and development charges...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  research and development charges t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>Subject: re : receipts from visit  jim ,  than...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  receipts from visit  jim   thanks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>Subject: re : enron case study update  wow ! a...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  enron case study update  wow  all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>Subject: re : interest  david ,  please , call...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  interest  david   please  call shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Subject: news : aurora 5 . 2 update  aurora ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject news  aurora 5  2 update  aurora versi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam  \\\n",
       "0     Subject: naturally irresistible your corporate...     1   \n",
       "1     Subject: the stock trading gunslinger  fanny i...     1   \n",
       "2     Subject: unbelievable new homes made easy  im ...     1   \n",
       "3     Subject: 4 color printing special  request add...     1   \n",
       "4     Subject: do not have money , get software cds ...     1   \n",
       "...                                                 ...   ...   \n",
       "5723  Subject: re : research and development charges...     0   \n",
       "5724  Subject: re : receipts from visit  jim ,  than...     0   \n",
       "5725  Subject: re : enron case study update  wow ! a...     0   \n",
       "5726  Subject: re : interest  david ,  please , call...     0   \n",
       "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0   \n",
       "\n",
       "                                             clean_text  \n",
       "0     subject naturally irresistible your corporate ...  \n",
       "1     subject the stock trading gunslinger  fanny is...  \n",
       "2     subject unbelievable new homes made easy  im w...  \n",
       "3     subject 4 color printing special  request addi...  \n",
       "4     subject do not have money  get software cds fr...  \n",
       "...                                                 ...  \n",
       "5723  subject re  research and development charges t...  \n",
       "5724  subject re  receipts from visit  jim   thanks ...  \n",
       "5725  subject re  enron case study update  wow  all ...  \n",
       "5726  subject re  interest  david   please  call shi...  \n",
       "5727  subject news  aurora 5  2 update  aurora versi...  \n",
       "\n",
       "[5728 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "df['clean_text'] = df.clean_text.map(lambda x: x.lower())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) Remove Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a function to remove numbers from the text. Apply it to `clean_text` ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:14:09.905508Z",
     "iopub.status.busy": "2025-08-12T11:14:09.903099Z",
     "iopub.status.idle": "2025-08-12T11:14:11.207005Z",
     "shell.execute_reply": "2025-08-12T11:14:11.205077Z",
     "shell.execute_reply.started": "2025-08-12T11:14:09.905455Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject naturally irresistible your corporate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject the stock trading gunslinger  fanny is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject unbelievable new homes made easy  im w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject  color printing special  request addit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject do not have money  get software cds fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>Subject: re : research and development charges...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  research and development charges t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>Subject: re : receipts from visit  jim ,  than...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  receipts from visit  jim   thanks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>Subject: re : enron case study update  wow ! a...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  enron case study update  wow  all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>Subject: re : interest  david ,  please , call...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  interest  david   please  call shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Subject: news : aurora 5 . 2 update  aurora ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject news  aurora    update  aurora version...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam  \\\n",
       "0     Subject: naturally irresistible your corporate...     1   \n",
       "1     Subject: the stock trading gunslinger  fanny i...     1   \n",
       "2     Subject: unbelievable new homes made easy  im ...     1   \n",
       "3     Subject: 4 color printing special  request add...     1   \n",
       "4     Subject: do not have money , get software cds ...     1   \n",
       "...                                                 ...   ...   \n",
       "5723  Subject: re : research and development charges...     0   \n",
       "5724  Subject: re : receipts from visit  jim ,  than...     0   \n",
       "5725  Subject: re : enron case study update  wow ! a...     0   \n",
       "5726  Subject: re : interest  david ,  please , call...     0   \n",
       "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0   \n",
       "\n",
       "                                             clean_text  \n",
       "0     subject naturally irresistible your corporate ...  \n",
       "1     subject the stock trading gunslinger  fanny is...  \n",
       "2     subject unbelievable new homes made easy  im w...  \n",
       "3     subject  color printing special  request addit...  \n",
       "4     subject do not have money  get software cds fr...  \n",
       "...                                                 ...  \n",
       "5723  subject re  research and development charges t...  \n",
       "5724  subject re  receipts from visit  jim   thanks ...  \n",
       "5725  subject re  enron case study update  wow  all ...  \n",
       "5726  subject re  interest  david   please  call shi...  \n",
       "5727  subject news  aurora    update  aurora version...  \n",
       "\n",
       "[5728 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "df['clean_text'] = df.clean_text.map(lambda x: ''.join(char for char in x if not char.isdigit()))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.4) Remove StopWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a function to remove stopwords from the text. Apply it to `clean_text`. ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:14:11.209171Z",
     "iopub.status.busy": "2025-08-12T11:14:11.208633Z",
     "iopub.status.idle": "2025-08-12T11:14:20.316866Z",
     "shell.execute_reply": "2025-08-12T11:14:20.314233Z",
     "shell.execute_reply.started": "2025-08-12T11:14:11.209121Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198 stopwords in English it seems!\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english')) # you can also choose other languages\n",
    "\n",
    "print(len(stop_words), 'stopwords in English it seems!')\n",
    "\n",
    "# First tokenize the sentencs, i.e. break them into list of words\n",
    "df['clean_text'] = df.clean_text.map(lambda wrd: [wrd for wrd in word_tokenize(df.clean_text.iloc[0]) if wrd not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:14:20.318889Z",
     "iopub.status.busy": "2025-08-12T11:14:20.318360Z",
     "iopub.status.idle": "2025-08-12T11:14:27.422386Z",
     "shell.execute_reply": "2025-08-12T11:14:27.420999Z",
     "shell.execute_reply.started": "2025-08-12T11:14:20.318842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject naturally irresistible corporate identity lt really hard recollect company market full suqgestions information isoverwhelminq good catchy logo stylish statlonery outstanding website make task much easy promise havinq order iogo company automaticaily become world ieader isguite ciear without good product effective business organization practicable aim hotat nowadays market promise market effort become much effective list clear benefit creativeness hand make original logo specially do reflect distinctive company image convenience logo stationery provide format easy use content management system letsyou change website content even structure promptness see logo draft within three business day affordability market break make gap budget satisfaction guarantee provide unlimited amount change extra fee surethat love result collaboration look portfolio interest'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "def lemmatizer(sentence):\n",
    "    tmp = ' '.join(w for w in [WordNetLemmatizer().lemmatize(word, pos='v') for word in sentence])\n",
    "    tmp = ' '.join(w for w in [WordNetLemmatizer().lemmatize(word, pos='n') for word in word_tokenize(tmp)])\n",
    "    tmp = ' '.join(w for w in [WordNetLemmatizer().lemmatize(word, pos='a') for word in word_tokenize(tmp)])\n",
    "    return tmp\n",
    "\n",
    "lemmatizer(df.clean_text.iloc[10])\n",
    "\n",
    "# ' '.join(w for w in [WordNetLemmatizer().lemmatize(word, pos='v') for word in df.clean_text.iloc[10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.5) Lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a function to lemmatize the text. Make sure the output is a single string, not a list of words. Apply it to `clean_text`. ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T11:14:44.627464Z",
     "iopub.status.busy": "2025-08-12T11:14:44.625313Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# (lambda x: ' '.join(w for w in [WordNetLemmatizer().lemmatize(word, pos='v') for word in x]))(df.clean_text.iloc[0])\n",
    "df['clean_text'] = df.clean_text.map(lambda x: lemmatizer(x))\n",
    "# df['clean_text'] = df.clean_text.map(lambda x: ' '.join(w for w in [WordNetLemmatizer().lemmatize(word, pos='a') for word in x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Bag-of-words Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) Digitizing the textual data into numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Vectorize the `clean_text` to a Bag-of-Words representation with a default CountVectorizer. Save as `X_bow`. ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T10:58:15.220949Z",
     "iopub.status.busy": "2025-08-12T10:58:15.220509Z",
     "iopub.status.idle": "2025-08-12T10:58:17.932375Z",
     "shell.execute_reply": "2025-08-12T10:58:17.930484Z",
     "shell.execute_reply.started": "2025-08-12T10:58:15.220908Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# lemma_text = df.clean_text.iloc[0]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# count_vect = CountVectorizer()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# X = count_vect.fit_transform([lemma_text])\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# X.toarray()\u001b[39;00m\n\u001b[1;32m      9\u001b[0m count_vect \u001b[38;5;241m=\u001b[39m CountVectorizer()\n\u001b[0;32m---> 10\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcount_vect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m X_bow \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# ?count_vect\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# df.clean_text.values\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1376\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1368\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1369\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1370\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1371\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1372\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1373\u001b[0m             )\n\u001b[1;32m   1374\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1376\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1379\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.9/envs/lewagon/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1282\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[0;32m-> 1282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1284\u001b[0m         )\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# lemma_text = df.clean_text.iloc[0]\n",
    "# count_vect = CountVectorizer()\n",
    "# X = count_vect.fit_transform([lemma_text])\n",
    "# X.toarray()\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X = count_vect.fit_transform(df.clean_text)\n",
    "X_bow = X.toarray()\n",
    "\n",
    "# ?count_vect\n",
    "# df.clean_text.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) Multinomial Naive Bayes Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Cross-validate a MultinomialNB model with the bag-of-words data. Score the model's accuracy. ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T09:42:24.562913Z",
     "iopub.status.busy": "2025-08-12T09:42:24.562381Z",
     "iopub.status.idle": "2025-08-12T09:42:24.664467Z",
     "shell.execute_reply": "2025-08-12T09:42:24.662501Z",
     "shell.execute_reply.started": "2025-08-12T09:42:24.562866Z"
    },
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "cv_results = cross_validate(MultinomialNB(), X_bow, df.spam.values, cv=5, scoring=['recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T09:42:25.463096Z",
     "iopub.status.busy": "2025-08-12T09:42:25.462642Z",
     "iopub.status.idle": "2025-08-12T09:42:25.471948Z",
     "shell.execute_reply": "2025-08-12T09:42:25.470621Z",
     "shell.execute_reply.started": "2025-08-12T09:42:25.463058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test_recall'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations !\n",
    "\n",
    "üíæ Don't forget to git add/commit/push your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-12T10:10:42.346581Z",
     "iopub.status.busy": "2025-08-12T10:10:42.344183Z",
     "iopub.status.idle": "2025-08-12T10:10:44.789760Z",
     "shell.execute_reply": "2025-08-12T10:10:44.787512Z",
     "shell.execute_reply.started": "2025-08-12T10:10:42.346069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master ee04ec1] ham or spam\n",
      " 1 file changed, 935 insertions(+), 29 deletions(-)\n",
      "Enumerating objects: 8, done.\n",
      "Counting objects: 100% (8/8), done.\n",
      "Delta compression using up to 4 threads\n",
      "Compressing objects: 100% (8/8), done.\n",
      "Writing objects: 100% (8/8), 5.79 KiB | 2.90 MiB/s, done.\n",
      "Total 8 (delta 1), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (1/1), done.\u001b[K\n",
      "To github.com:roninrp/data-ham-or-spam.git\n",
      " * [new branch]      master -> master\n"
     ]
    }
   ],
   "source": [
    "!git add 01-Ham-or-Spam.ipynb\n",
    "\n",
    "! git commit -m \"ham or spam\"\n",
    "\n",
    "! git push origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
